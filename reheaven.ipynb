{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MIvak6MSJie",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "outputId": "e99acc91-2087-4c47-da75-fb99dbf91561"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive',force_remount=True)\n",
        "!pip install transformers\n",
        "\n",
        "import torch\n",
        "import sys\n",
        "import transformers\n",
        "sys.path.append('/gdrive/My Drive/my_transformers')\n",
        "sys.path.append('/gdrive/My Drive')\n",
        "from my_transformers import(\n",
        "    ElectraConfig,\n",
        "    ElectraForSequenceClassification,\n",
        "    ElectraTokenizer,\n",
        ")\n",
        "\n",
        "\n",
        "labels = ['0', '1']\n",
        "\n",
        "config = ElectraConfig.from_pretrained(\n",
        "            \"monologg/koelectra-base-discriminator\",\n",
        "            num_labels=2,\n",
        "            id2label={str(i): label for i, label in enumerate(labels)},\n",
        "            label2id={label: i for i, label in enumerate(labels)},\n",
        "        )\n",
        "\n",
        "model = ElectraForSequenceClassification(config)\n",
        "loaded = torch.load(\"/gdrive/My Drive/model_weight/pytorch_model.bin\",map_location='cpu')  #torch.load(PATH,map_location), map_location은 model을 load하는 device 종류\n",
        "model.load_state_dict(loaded,strict=False)\n",
        "\n",
        "tokenizer = ElectraTokenizer.from_pretrained(\"monologg/koelectra-base-discriminator\")\n",
        "\n",
        "with open('/gdrive/My Drive/test_output.txt','w',encoding='utf-8') as fd_write:\n",
        "  with open('/gdrive/My Drive/test_input.txt','r',encoding='utf-8') as fd_read:\n",
        "    for sentence in fd_read.readlines():\n",
        "\n",
        "      tokenized_sentence= tokenizer.tokenize(sentence)\n",
        "\n",
        "      print('generated tokens: ',tokenized_sentence)\n",
        "\n",
        "      gen_encoded = tokenizer.encode(tokenized_sentence, return_tensors=\"pt\") # model내 vocabulary에 있는 id로 토큰을 mapping(encoding)\n",
        "\n",
        "      model_input = gen_encoded\n",
        "\n",
        "      classification_result = model(model_input)\n",
        "\n",
        "      print(classification_result)\n",
        "\n",
        "      result = torch.argmax(classification_result[0])\n",
        "      if result:\n",
        "        print(sentence,'= 긍정')\n",
        "        fd_write.write((str(1)+'\\n'))\n",
        "      else:\n",
        "        print(sentence,'= 부정')\n",
        "        fd_write.write((str(0)+'\\n'))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (3.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tokenizers==0.8.1.rc2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8.1rc2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "generated tokens:  ['슬프', '##지만', '마음', '따뜻', '##해지는', '영화']\n",
            "(tensor([[-2.0672,  2.3852]], grad_fn=<AddmmBackward>),)\n",
            "슬프지만 마음 따뜻해지는 영화\n",
            " = 긍정\n",
            "generated tokens:  ['음악', '연출', '스토리', '좋', '##았', '##음', '.', '.', '대만', '##영화', '중', '최고', '##인', '##듯']\n",
            "(tensor([[-2.5859,  3.0954]], grad_fn=<AddmmBackward>),)\n",
            "음악 연출 스토리 좋았음..대만영화 중 최고인듯\n",
            " = 긍정\n",
            "generated tokens:  ['관객', '##을', '모욕', '##한', '영화']\n",
            "(tensor([[ 3.2676, -3.1734]], grad_fn=<AddmmBackward>),)\n",
            "관객을 모욕한 영화\n",
            " = 부정\n",
            "generated tokens:  ['음악', '하', '##난', '죽여', '##주', '##네']\n",
            "(tensor([[-1.6261,  1.9243]], grad_fn=<AddmmBackward>),)\n",
            "음악 하난 죽여주네\n",
            " = 긍정\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYRrT63YjNLf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}