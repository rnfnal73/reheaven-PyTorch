{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "reheaven.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MIvak6MSJie",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive',force_remount=True)\n",
        "!pip install transformers\n",
        "\n",
        "import torch\n",
        "import sys\n",
        "import transformers\n",
        "sys.path.append('/gdrive/My Drive/reheaven-PyTorch-master/my_transformers')\n",
        "sys.path.append('/gdrive/My Drive/reheaven-PyTorch-master')\n",
        "from my_transformers import(\n",
        "    ElectraConfig,\n",
        "    ElectraForSequenceClassification,\n",
        "    ElectraTokenizer,\n",
        ")\n",
        "\n",
        "\n",
        "labels = ['0', '1']\n",
        "\n",
        "config = ElectraConfig.from_pretrained(\n",
        "            \"/gdrive/My Drive/reheaven-PyTorch-master/model_weight/wordpiece_base\",\n",
        "            num_labels=2,\n",
        "            id2label={str(i): label for i, label in enumerate(labels)},\n",
        "            label2id={label: i for i, label in enumerate(labels)},\n",
        "            )\n",
        "\n",
        "model = ElectraForSequenceClassification.from_pretrained(\n",
        "            \"/gdrive/My Drive/reheaven-PyTorch-master/model_weight/wordpiece_base\",\n",
        "            from_tf=True,\n",
        "            config=config\n",
        "            )\n",
        "loaded = torch.load(\"/gdrive/My Drive/reheaven-PyTorch-master/model_weight/pytorch_model.bin\",map_location='cpu')  #torch.load(PATH,map_location), map_location은 model을 load하는 device 종류\n",
        "model.load_state_dict(loaded,strict=False)\n",
        "\n",
        "tokenizer = ElectraTokenizer.from_pretrained(\"/gdrive/My Drive/reheaven-PyTorch-master/model_weight/wordpiece_base\")\n",
        "\n",
        "with open('/gdrive/My Drive/reheaven-PyTorch-master/test_output.txt','w',encoding='utf-8') as fd_write:\n",
        "  with open('/gdrive/My Drive/reheaven-PyTorch-master/test_input.txt','r',encoding='utf-8') as fd_read:\n",
        "    for sentence in fd_read.readlines():\n",
        "\n",
        "      tokenized_sentence= tokenizer.tokenize(sentence)\n",
        "\n",
        "\n",
        "      gen_encoded = tokenizer.encode(tokenized_sentence, return_tensors=\"pt\") # model내 vocabulary에 있는 id로 토큰을 mapping(encoding)\n",
        "\n",
        "      model_input = gen_encoded\n",
        "\n",
        "      classification_result = model(model_input)\n",
        "\n",
        "      result = torch.argmax(classification_result[0])\n",
        "      if result:\n",
        "        fd_write.write((str(1)+'\\n'))\n",
        "      else:\n",
        "        fd_write.write((str(0)+'\\n'))\n",
        "print('\\ndone')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYRrT63YjNLf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}